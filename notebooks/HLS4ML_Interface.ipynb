{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 17:47:22.433113: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-01 17:47:23.977054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/miniconda3/envs/ml-env/lib/python3.8/site-packages/hls4ml/converters/__init__.py:25: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import hls4ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MaxPooling2D, Input, concatenate, Conv2D, Activation, ZeroPadding2D, UpSampling2D, add\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.models import *\n",
    "from qkeras import *\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "wl00sZb4Mm2W",
    "outputId": "914f8c83-7d5c-4342-ab33-122d5dd8de00"
   },
   "outputs": [],
   "source": [
    "# import load_model\n",
    "import datetime\n",
    "import os\n",
    "from enum import Enum\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oJrr_RJsOGNn"
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \"\"\n",
    "data_dir = BASE_PATH+''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVCmTos-OeM0"
   },
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "\n",
    "model_dir = \"/nfs_scratch/hsharma/MachineLearning/ClusterFinder/notebooks/wandb/run-20230711_144156-d0m662qq/files/\"\n",
    "model_name = 'model-best.h5'\n",
    "\n",
    "model = load_model(\n",
    "    model_dir + model_name,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNETLiteV4Model:\n",
    "    '''\n",
    "    Build UNET based model for segmentation task.\n",
    "    '''\n",
    "    def prepare_model(self, OUTPUT_CHANNEL, input_size=(30,30,1)):\n",
    "        inputs = Input(input_size)\n",
    "\n",
    "        conv1, pool1 = self.__ConvBlock(4, (3,3), (2,2), 'relu', 'same', inputs) \n",
    "        conv2, up3 = self.__UpConvBlock(8, 4, (3,3), (2,2), (2,2), 'relu', 'same', pool1, conv1)\n",
    "\n",
    "        conv4 = self.__ConvBlock(4, (3,3), (2,2), 'relu', 'same', up3, False)\n",
    "\n",
    "        outputs = Conv2D(OUTPUT_CHANNEL, (3, 3), activation='softmax', padding='same')(conv4)\n",
    "\n",
    "        return Model(inputs=[inputs], outputs=[outputs])  \n",
    "\n",
    "    def __ConvBlock(self, filters, kernel_size, pool_size, activation, padding, connecting_layer, pool_layer=True):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n",
    "        if pool_layer:\n",
    "            pool = MaxPooling2D(pool_size)(conv)\n",
    "            return conv, pool\n",
    "        else:\n",
    "            return conv\n",
    "\n",
    "    def __UpConvBlock(self, filters, up_filters, kernel_size, up_kernel, up_stride, activation, padding, connecting_layer, shared_layer):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n",
    "        up = UpSampling2D((2,2))(conv)\n",
    "        up = Conv2D(up_filters, (1, 1), activation='relu', kernel_initializer='he_normal', padding='same')(up)\n",
    "        up = concatenate([up, shared_layer], axis=3)\n",
    "\n",
    "        return conv, up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 30, 30, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 30, 30, 4)    40          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 30, 30, 4)    148         ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 15, 15, 4)   0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 15, 15, 8)    296         ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 15, 15, 8)    584         ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 30, 30, 8)    0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 30, 30, 4)    36          ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 30, 30, 8)    0           ['conv2d_11[0][0]',              \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 30, 30, 4)    292         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 30, 30, 4)    148         ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 30, 30, 3)    111         ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,655\n",
      "Trainable params: 1,655\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# output channel is 3 because we have three classes in our mask\n",
    "model = UNETLiteV4Model().prepare_model(3, input_size=(30, 30, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 10, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 10, 10, 4)    40          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 10, 10, 4)    148         ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 5, 5, 4)      0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 5, 5, 8)      296         ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 5, 5, 8)      584         ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 10, 10, 4)   132         ['conv2d_3[0][0]']               \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 10, 10, 8)    0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 10, 10, 4)    292         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 10, 10, 4)    148         ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,640\n",
      "Trainable params: 1,640\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "all_layers_except_last = model.layers[:-1]\n",
    "model = Model(inputs=model.input, outputs=all_layers_except_last[-1].output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "fEL-yoyIMdia"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_2, layer type: InputLayer, input shapes: [[None, 30, 30, 1]], output shape: [None, 30, 30, 1]\n",
      "Layer name: conv2d_7, layer type: Conv2D, input shapes: [[None, 30, 30, 1]], output shape: [None, 30, 30, 4]\n",
      "Layer name: conv2d_8, layer type: Conv2D, input shapes: [[None, 30, 30, 4]], output shape: [None, 30, 30, 4]\n",
      "Layer name: max_pooling2d_1, layer type: MaxPooling2D, input shapes: [[None, 30, 30, 4]], output shape: [None, 15, 15, 4]\n",
      "Layer name: conv2d_9, layer type: Conv2D, input shapes: [[None, 15, 15, 4]], output shape: [None, 15, 15, 8]\n",
      "Layer name: conv2d_10, layer type: Conv2D, input shapes: [[None, 15, 15, 8]], output shape: [None, 15, 15, 8]\n",
      "Layer name: up_sampling2d, layer type: UpSampling2D, input shapes: [[None, 15, 15, 8]], output shape: [None, 30, 30, 8]\n",
      "Layer name: conv2d_11, layer type: Conv2D, input shapes: [[None, 30, 30, 8]], output shape: [None, 30, 30, 4]\n",
      "Layer name: concatenate_1, layer type: Concatenate, input shapes: [[None, 30, 30, 4], [None, 30, 30, 4]], output shape: [None, 30, 30, 8]\n",
      "Layer name: conv2d_12, layer type: Conv2D, input shapes: [[None, 30, 30, 8]], output shape: [None, 30, 30, 4]\n",
      "Layer name: conv2d_13, layer type: Conv2D, input shapes: [[None, 30, 30, 4]], output shape: [None, 30, 30, 4]\n",
      "Layer name: conv2d_14, layer type: Conv2D, input shapes: [[None, 30, 30, 4]], output shape: [None, 30, 30, 3]\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_2, layer type: InputLayer, input shapes: [[None, 30, 30, 1]], output shape: [None, 30, 30, 1]\n",
      "Layer name: conv2d_7, layer type: Conv2D, input shapes: [[None, 30, 30, 1]], output shape: [None, 30, 30, 4]\n",
      "Layer name: conv2d_8, layer type: Conv2D, input shapes: [[None, 30, 30, 4]], output shape: [None, 30, 30, 4]\n",
      "Layer name: max_pooling2d_1, layer type: MaxPooling2D, input shapes: [[None, 30, 30, 4]], output shape: [None, 15, 15, 4]\n",
      "Layer name: conv2d_9, layer type: Conv2D, input shapes: [[None, 15, 15, 4]], output shape: [None, 15, 15, 8]\n",
      "Layer name: conv2d_10, layer type: Conv2D, input shapes: [[None, 15, 15, 8]], output shape: [None, 15, 15, 8]\n",
      "Layer name: up_sampling2d, layer type: UpSampling2D, input shapes: [[None, 15, 15, 8]], output shape: [None, 30, 30, 8]\n",
      "Layer name: conv2d_11, layer type: Conv2D, input shapes: [[None, 30, 30, 8]], output shape: [None, 30, 30, 4]\n",
      "Layer name: concatenate_1, layer type: Concatenate, input shapes: [[None, 30, 30, 4], [None, 30, 30, 4]], output shape: [None, 30, 30, 8]\n",
      "Layer name: conv2d_12, layer type: Conv2D, input shapes: [[None, 30, 30, 8]], output shape: [None, 30, 30, 4]\n",
      "Layer name: conv2d_13, layer type: Conv2D, input shapes: [[None, 30, 30, 4]], output shape: [None, 30, 30, 4]\n",
      "Layer name: conv2d_14, layer type: Conv2D, input shapes: [[None, 30, 30, 4]], output shape: [None, 30, 30, 3]\n",
      "Creating HLS model\n",
      "WARNING: Layer conv2d_7 requires \"dataflow\" pipeline style. Switching to \"dataflow\" pipeline style.\n",
      "WARNING: Config parameter \"trace\" overwrites an existing attribute in layer \"conv2d_11\" (PointwiseConv2D)\n",
      "WARNING: Config parameter \"precision\" overwrites an existing attribute in layer \"conv2d_11\" (PointwiseConv2D)\n",
      "WARNING: Config parameter \"strategy\" overwrites an existing attribute in layer \"conv2d_11\" (PointwiseConv2D)\n",
      "WARNING: Config parameter \"reuse_factor\" overwrites an existing attribute in layer \"conv2d_11\" (PointwiseConv2D)\n"
     ]
    }
   ],
   "source": [
    "#First, the baseline model\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "# Set the precision and reuse factor for the full model\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "hls_config['Model']['ReuseFactor'] = 1\n",
    "\n",
    "# Create an entry for each layer, here you can for instance change the strategy for a layer to 'resource' \n",
    "# or increase the reuse factor individually for large layers.\n",
    "# In this case, we designed the model to be small enough for a fully parallel implementation \n",
    "# so we use the latency strategy and reuse factor of 1 for all layers.\n",
    "for Layer in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][Layer]['Strategy'] = 'latency'\n",
    "    hls_config['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "#If you want best numerical performance for high-accuray models, while the default latency strategy is faster but numerically more unstable\n",
    "sm_layer = list(hls_config[\"LayerName\"].keys())[-1]\n",
    "hls_config['LayerName'][sm_layer]['Strategy'] = 'stable'\n",
    "#plotting.print_dict(hls_config)\n",
    "\n",
    "cfg = hls4ml.converters.create_config(backend='Vivado')\n",
    "cfg['IOType']     = 'io_stream' # Must set this if using CNNs!\n",
    "cfg['HLSConfig']  = hls_config\n",
    "cfg['KerasModel'] = model\n",
    "cfg['OutputDir']  = 'fpga_1800_30x30_xcvu13_nclock/'\n",
    "cfg['Part'] = 'xcvu13p-flga2577-2-e'\n",
    "cfg['ClockPeriod'] = 2.777778\n",
    "cfg['ClockUncertainty'] = \"30.0%\"\n",
    "#cfg['XilinxPart'] = 'xcu250-figd2104-2L-e'\n",
    "#cfg['XilinxPart'] = \"xczu9eg-2ffvb1156\"\n",
    "\n",
    "  \n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 10, 10, 1]], output shape: [None, 10, 10, 1]\n",
      "Layer name: conv2d, layer type: Conv2D, input shapes: [[None, 10, 10, 1]], output shape: [None, 10, 10, 3]\n",
      "Layer name: conv2d_1, layer type: Conv2D, input shapes: [[None, 10, 10, 3]], output shape: [None, 10, 10, 3]\n",
      "Layer name: max_pooling2d, layer type: MaxPooling2D, input shapes: [[None, 10, 10, 3]], output shape: [None, 5, 5, 3]\n",
      "Layer name: conv2d_2, layer type: Conv2D, input shapes: [[None, 5, 5, 3]], output shape: [None, 5, 5, 4]\n",
      "Layer name: conv2d_3, layer type: Conv2D, input shapes: [[None, 5, 5, 4]], output shape: [None, 5, 5, 4]\n",
      "Layer name: up_sampling2d, layer type: UpSampling2D, input shapes: [[None, 5, 5, 4]], output shape: [None, 10, 10, 4]\n",
      "Layer name: conv2d_4, layer type: Conv2D, input shapes: [[None, 10, 10, 4]], output shape: [None, 10, 10, 4]\n",
      "Layer name: concatenate, layer type: Concatenate, input shapes: [[None, 10, 10, 4], [None, 10, 10, 3]], output shape: [None, 10, 10, 7]\n",
      "Layer name: conv2d_5, layer type: Conv2D, input shapes: [[None, 10, 10, 7]], output shape: [None, 10, 10, 3]\n",
      "Layer name: conv2d_6, layer type: Conv2D, input shapes: [[None, 10, 10, 3]], output shape: [None, 10, 10, 3]\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 10, 10, 1]], output shape: [None, 10, 10, 1]\n",
      "Layer name: conv2d, layer type: Conv2D, input shapes: [[None, 10, 10, 1]], output shape: [None, 10, 10, 3]\n",
      "Layer name: conv2d_1, layer type: Conv2D, input shapes: [[None, 10, 10, 3]], output shape: [None, 10, 10, 3]\n",
      "Layer name: max_pooling2d, layer type: MaxPooling2D, input shapes: [[None, 10, 10, 3]], output shape: [None, 5, 5, 3]\n",
      "Layer name: conv2d_2, layer type: Conv2D, input shapes: [[None, 5, 5, 3]], output shape: [None, 5, 5, 4]\n",
      "Layer name: conv2d_3, layer type: Conv2D, input shapes: [[None, 5, 5, 4]], output shape: [None, 5, 5, 4]\n",
      "Layer name: up_sampling2d, layer type: UpSampling2D, input shapes: [[None, 5, 5, 4]], output shape: [None, 10, 10, 4]\n",
      "Layer name: conv2d_4, layer type: Conv2D, input shapes: [[None, 10, 10, 4]], output shape: [None, 10, 10, 4]\n",
      "Layer name: concatenate, layer type: Concatenate, input shapes: [[None, 10, 10, 4], [None, 10, 10, 3]], output shape: [None, 10, 10, 7]\n",
      "Layer name: conv2d_5, layer type: Conv2D, input shapes: [[None, 10, 10, 7]], output shape: [None, 10, 10, 3]\n",
      "Layer name: conv2d_6, layer type: Conv2D, input shapes: [[None, 10, 10, 3]], output shape: [None, 10, 10, 3]\n",
      "Creating HLS model\n",
      "WARNING: Strategy for layer input_1 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d_relu set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d_1 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d_1_relu set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer max_pooling2d set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d_2 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d_2_relu set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d_3 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d_3_relu set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer up_sampling2d set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d_4 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d_4_relu set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer concatenate set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d_5 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d_5_relu set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d_6 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2d_6_relu set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Changing pipeline style to \"dataflow\".\n",
      "WARNING: Invalid ReuseFactor=4 in layer \"conv2d\".Using ReuseFactor=3 instead. Valid ReuseFactor(s): 1,3,9,27.\n",
      "WARNING: Invalid ParallelizationFactor=3 in layer \"conv2d\".Using ParallelizationFactor=2 instead. Valid ParallelizationFactor(s): 1,2,4,5,10,20,25,50,100.\n",
      "WARNING: Invalid ReuseFactor=4 in layer \"conv2d_1\".Using ReuseFactor=3 instead. Valid ReuseFactor(s): 1,3,9,27,81.\n",
      "WARNING: Invalid ParallelizationFactor=3 in layer \"conv2d_1\".Using ParallelizationFactor=2 instead. Valid ParallelizationFactor(s): 1,2,4,5,10,20,25,50,100.\n",
      "WARNING: Invalid ReuseFactor=4 in layer \"conv2d_2\".Using ReuseFactor=3 instead. Valid ReuseFactor(s): 1,3,9,27,54,108.\n",
      "WARNING: Invalid ParallelizationFactor=3 in layer \"conv2d_2\".Using ParallelizationFactor=1 instead. Valid ParallelizationFactor(s): 1,5,25.\n",
      "WARNING: Invalid ParallelizationFactor=3 in layer \"conv2d_3\".Using ParallelizationFactor=1 instead. Valid ParallelizationFactor(s): 1,5,25.\n",
      "WARNING: Invalid ParallelizationFactor=3 in layer \"conv2d_4\".Using ParallelizationFactor=2 instead. Valid ParallelizationFactor(s): 1,2,4,5,10,20,25,50,100.\n",
      "WARNING: Invalid ReuseFactor=4 in layer \"conv2d_5\".Using ReuseFactor=3 instead. Valid ReuseFactor(s): 1,3,7,9,21,63,189.\n",
      "WARNING: Invalid ParallelizationFactor=3 in layer \"conv2d_5\".Using ParallelizationFactor=2 instead. Valid ParallelizationFactor(s): 1,2,4,5,10,20,25,50,100.\n",
      "WARNING: Invalid ReuseFactor=4 in layer \"conv2d_6\".Using ReuseFactor=3 instead. Valid ReuseFactor(s): 1,3,9,27,81.\n",
      "WARNING: Invalid ParallelizationFactor=3 in layer \"conv2d_6\".Using ParallelizationFactor=2 instead. Valid ParallelizationFactor(s): 1,2,4,5,10,20,25,50,100.\n",
      "WARNING: Config parameter \"trace\" overwrites an existing attribute in layer \"conv2d_4\" (PointwiseConv2D)\n",
      "WARNING: Config parameter \"precision\" overwrites an existing attribute in layer \"conv2d_4\" (PointwiseConv2D)\n",
      "WARNING: Config parameter \"strategy\" overwrites an existing attribute in layer \"conv2d_4\" (PointwiseConv2D)\n",
      "WARNING: Config parameter \"reuse_factor\" overwrites an existing attribute in layer \"conv2d_4\" (PointwiseConv2D)\n",
      "WARNING: Config parameter \"parallelization_factor\" overwrites an existing attribute in layer \"conv2d_4\" (PointwiseConv2D)\n",
      "WARNING: Config parameter \"accum\" overwrites an existing attribute in layer \"conv2d_4\" (PointwiseConv2D)\n",
      "WARNING: Config parameter \"result\" overwrites an existing attribute in layer \"conv2d_4\" (PointwiseConv2D)\n"
     ]
    }
   ],
   "source": [
    "hls4ml.model.optimizer.get_optimizer(\n",
    "    'output_rounding_saturation_mode'\n",
    ").configure(\n",
    "    layers=['relu1', 'relu2'],\n",
    "    rounding_mode='AP_RND',\n",
    "    saturation_mode='AP_SAT',\n",
    "    saturation_bits='AP_SAT'\n",
    ")\n",
    "hls4ml.model.optimizer.get_optimizer(\n",
    "    'eliminate_linear_activation'\n",
    ")\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(\n",
    "    model,\n",
    "    granularity='name'\n",
    ")\n",
    "\n",
    "hls_config['Model']['ReuseFactor'] = 1\n",
    "hls_config['Model']['Strategy'] = 'Resource'\n",
    "hls_config['Model']['ClockPeriod']  = 6.25\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<16, 6>'\n",
    "# hls_config['Model']['Trace']  = True\n",
    "\n",
    "for layer in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][layer]['Strategy'] = 'Resource'\n",
    "    hls_config['LayerName'][layer]['ReuseFactor'] = 4\n",
    "    # hls_config['LayerName'][layer]['Trace'] = True\n",
    "\n",
    "hls_config['LayerName']['input_1']['Precision']['accum'] = 'ap_uint<10>'\n",
    "hls_config['LayerName']['input_1']['Precision']['result'] = 'ap_uint<10>'\n",
    "\n",
    "for layer in hls_config['LayerName'].keys():\n",
    "    if \"conv2d\" in layer:\n",
    "        hls_config['LayerName'][layer]['ParallelizationFactor'] = 3\n",
    "        hls_config['LayerName'][layer]['accum'] = 'ap_fixed<20, 8>'\n",
    "        hls_config['LayerName'][layer]['result'] = 'ap_fixed<15, 8>'\n",
    "\n",
    "cfg = hls4ml.converters.create_config(part=\"xc7vx690tffg1927-2\")\n",
    "\n",
    "cfg['IOType'] = 'io_parallel'\n",
    "cfg['HLSConfig'] = hls_config\n",
    "cfg['KerasModel'] = model\n",
    "cfg['ClockPeriod']  = 6.25\n",
    "cfg['OutputDir']  = 'fpga_model_700_cnn_wosm/'\n",
    "cfg['Part'] = 'xc7vx690tffg1927-2'\n",
    "\n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKnC_g4QNDI9"
   },
   "outputs": [],
   "source": [
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=\"UNL_12distill.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hls4ml.model import profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4K3p_Uc4NDK2"
   },
   "outputs": [],
   "source": [
    "profiling.numerical(model=model, hls_model=hls_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras.qtools import run_qtools\n",
    "from qkeras.qtools import settings as qtools_settings\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "from qkeras import quantized_bits\n",
    "from qkeras import QDense, QActivation\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy Profiling dmodel: Student w/o Quantization\n",
    "q = run_qtools.QTools(model, \n",
    "                      process=\"horowitz\", \n",
    "                      source_quantizers=[quantized_bits(16, 5, 1)], \n",
    "                      is_inference=True, \n",
    "                      weights_path=None,\n",
    "                      keras_quantizer=\"fp16\",\n",
    "                      keras_accumulator=\"fp16\", \n",
    "                      for_reference=False)\n",
    "q.qtools_stats_print()\n",
    "\n",
    "energy_dict = q.pe(\n",
    "    weights_on_memory=\"fixed\",\n",
    "    activations_on_memory=\"fixed\",\n",
    "    min_sram_size=8*16*1024*1024,\n",
    "    rd_wr_on_io=False)\n",
    "\n",
    "# get stats of energy distribution in each layer\n",
    "energy_profile = q.extract_energy_profile(\n",
    "    qtools_settings.cfg.include_energy, energy_dict)\n",
    "# extract sum of energy of each layer according to the rule specified in\n",
    "# qtools_settings.cfg.include_energy\n",
    "total_energy = q.extract_energy_sum(\n",
    "    qtools_settings.cfg.include_energy, energy_dict)\n",
    "\n",
    "pprint.pprint(energy_profile)\n",
    "print()\n",
    "\n",
    "print(\"Total energy: {:.6f} uJ\".format(total_energy / 1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
